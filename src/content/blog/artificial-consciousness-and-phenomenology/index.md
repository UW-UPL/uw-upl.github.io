---
title: Artificial Consciousness and Phenomenology
pubDate: "2022-03-12"
author: Reed Nelson
---

Perceptions of what it takes for a computer to have consciousness seem to vary radically from person to person. If you have very low standards, perhaps you think it possible that the internet, or even just individual computers already have some level of consciousness. At the other extreme, you could think real artificial consciousness is centuries off or even impossible[^0]. I decided to write about this topic because odds are, I think your standards are too low. My goal in this post is to make you consider aspects of consciousness you might not have before, and perhaps give you cause to update your intuition.

To get us on the same page and in the right headspace, I’ll define a few terms before moving forward. Artificial narrow intelligences (ANIs) are systems capable of doing a narrow range of tasks, usually as well or better than a human could. This describes all present-day AIs (think Deep Blue, AlphaZero, GPT-3, Alexa…).  Artificial General Intelligence (AGI) refers to a system that can do most everything an average human can, at least in feats of intellect. Consciousness can be a tricky thing to talk and think about. There are at least a dozen named theories as to what broadly is going on in the mind/brain to create consciousness. We’ll define it as Google does: “the fact of awareness by the mind of itself and the world”.  

Notice that our definition of AGI says absolutely nothing about consciousness! If you can agree that the bits moving through caches to tell you an optimal chess move do not constitute consciousness, then you should also agree that the concatenation of this functionality with a million other individual human-like functions still doesn’t sum to consciousness. And of course, don’t be fooled by sophisticated chat bots or computer vision algorithms. What’s going on under the hood is fundamentally the same, with respect to our concerns in this discussion. This is all to say, you can theoretically have AGI without consciousness. 

At this point you might be asking yourself “but Reed, it can do things! What does it matter whether it has consciousness?”. I leave this question as an exercise to the reader.[^1]


### Phenoumenomonie?

Now for the fun part: unusual and out-of-fashion philosophy. The Phenomenological tradition was started by Edmund Husserl and was present in the works of a number of notable European philosophers of the early-mid 20th century. Phenomenology is essentially (if you can believe it) the study of phenomena. Phenomenology puts first the subjective first-personal experience, the what-it’s-like-ness of a phenomenon, and considers second the aspect of a phenomenon that one thinks about, that one can describe with words and conventionally analyze. I believe a phenomenological approach to the question of what it takes to create consciousness is critical, because it gets at the heart of the difference between our minds and machines. 

For the sake of precision, I would like to introduce just one more term: Dasein[^2]. To avoid bogging us down, consider Dasein to be a generic term for a being with human-like consciousness. We want to avoid the word human to underscore that we're not talking about properties that are necessarily exclusive to humans. E.g. if we contacted an alien society, and they did math and had complex relationships and whatever else distinguishes humans from other Earthly animals in the relevant respects, we'd say members of this alien race are Dasein.  

So then, what exactly are the differences, phenomenologically speaking, between dasein, and the likes of chairs and computers? To Heidegger, these were some of the biggest things:

1. Dasein’s Being is Being-in-the-world: It is in the world, not merely in the passive, spatial sense of the word ‘in’, but in an active sense exclusive to Dasein. That is, it dwells in, it engages in the world.
2. For Dasein, entities are fundamentally ready-to-hand[^3]: The pre-reflective experience of things in the world for Dasein is not as objects with explicit properties, but as equipment, entities to be understood through their use. E.g., when in a room, we don't encounter the room in a geometric sense, as something between four walls, but rather as equipment for residing. This is a further implication of the Dasein’s inherent concern with its Being: because Dasein lives in the world, and interacts with the things in it, those things carry meaning for it, insofar as they relate in some way to its undertakings. 
3. Dasein has mineness: Unlike ordinary objects, Dasein cares about what it is, what its life is amounting to. Emerging from this concern with its own being, Dasein has a first-person perspective. As such, one uses a personal pronoun when addressing it, i.e. ‘I am’, ‘you are’.
4. Dasein *has* a way of Being: It has personality, social roles, a lifestyle. In its understanding that it is one way rather than another, it understands what it is to be. 
5. Dasein *is* its way of Being: “The ‘essence’ of dasein lies in its existence”[^4]. Unlike ordinary entities such as chairs or baseballs, its Being is what it chooses to make of its properties. The difference is that a chair’s Being is totally static, it cannot be any other way. It has no mineness, and no concern with its own (or any) Being. On the other hand, Dasein’s Being is dynamic. Through its own volition, it determines how it acts, and thus, how it is.


### The Upshot
You need not completely understand these or comletely agree that they're all necessary for what we want to call a humanlike level of consciousness. But if you get the gist and you can convince yourself that some of these are capturing important differences between the conscious and the not, then the thought that the internet or even some superhuman chat bot could have consciousness should sound completely absurd. 

An obvious next step would be to theorize about how we actually go from plain AGI to Dasein AGI, but I feel we're running long, and that could be a blog post all its own. 

---

### Additional Reading

#### Alan Turing - [Computing Machinery and Intelligence](https://academic.oup.com/mind/article/LIX/236/433/986238) (1950) 

This is one of Turing’s most famous papers. This is where the [Turing Test](https://en.wikipedia.org/wiki/Turing_test) debuted, and its among the earliest works in this domain. And it’s a remarkably easy read for its age! 

#### John Searle - [Minds, Brains, and Programs](https://www.law.upenn.edu/live/files/3413-searle-j-minds-brains-and-programs-1980pdf) (1980) 

Like Turing’s, this work is also famous for its thought experiment: the [Chinese Room](https://en.wikipedia.org/wiki/Chinese_room). The Chinese Room is meant to show that a machine’s ability to pass the Turing test is no measure of its ability to think, in a human-ish sense. I find the argument pretty convincing, and I suspect most do.

Fun fact: Searle did undergrad at UW!

#### Hubert Dreyfus - [What Computers (Still) Can’t Do](https://www.penguin.com.au/books/what-computers-still-cant-do-9780262540674) (1972/1992) 

This is a whole book. I can’t say whether it’s all worth reading, but there are certainly some interesting takeaways if you can find a summary. Hubert and his brother Stuart developed a [model of skill acquisition](https://www.kaizenko.com/the-dreyfus-model-of-skills-acquisition/), with which they argue that machines could never develop the skills humans do, in the depth that we do them. This is because while computers operate solely on explicit instruction, skills that humans excel at are executed with a high degree of “tacit knowledge” that cannot be reduced to explicit instructions (think muscle memory, kind of). However, many significant milestones have been passed since this book’s publication, and there now exists AI which can handle tacit knowledge pretty well. 

#### Ragnar Fjelland - [Why General Artificial Intelligence will not be Realized](https://www.nature.com/articles/s41599-020-0494-4) (2020) 

Fjelland’s goal in this paper is to show that Dreyfus’s argument still holds, despite the extensive development of artificial neural networks. He argues that modern methods (e.g. ML) are merely correlative, they know nothing of causation. A higher level of reasoning, with a deeper understanding of the events in question and the context they occured in is necessary to determine causation. Thus, a machine that is not in-the-world cannot reason about causal relationships. 

>“We are bodily and social beings, living in a material and social world. To understand another person is not to look into the chemistry of that person’s brain, not even into that person’s soul, but is rather to be in that person’s ‘shoes’. It is to understand that person’s lifeworld.” 

---

[^0]: And you’d be in the company of [some experts](https://www.researchgate.net/publication/280838978_Future_Progress_in_Artificial_Intelligence_A_Survey_of_Expert_Opinion)!
[^1]: I've always wanted to say this.
[^2]: Pronounced däzīn. This is a German word which just means "being there". Our usage comes from Martin Heidegger (phenomenologist and student of Husserl). Dasein is a very important and nuanced concept for Heidegger, we're being a little fast and loose.
[^3]: "Zuhandenheit", in German. Contrast this with a *present-at-hand* ("vorhandenheit") approach: perception of the world as objects with articulable properties.  
[^4]: Heidegger, [Being and Time](http://www.naturalthinker.net/trl/texts/Heidegger,Martin/Heidegger,%20Martin%20-%20Being%20and%20Time/Being%20and%20Time.pdf).
